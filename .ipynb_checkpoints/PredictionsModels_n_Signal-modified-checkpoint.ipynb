{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "367b83c4-b188-48a3-8ef0-e87a826311b6",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Prections using the different models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e68a2ca0-c75b-4fc9-8ae2-1c0a09ea4e43",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'tensorflow'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_3328/193911312.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;31m#import hvplot.pandas\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mtensorflow\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mpathlib\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mPath\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'tensorflow'"
     ]
    }
   ],
   "source": [
    "# Import Libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import hvplot.pandas\n",
    "import tensorflow as tf\n",
    "from pathlib import Path\n",
    "\n",
    "# API import\n",
    "import requests\n",
    "import json\n",
    "import pickle as pk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f0310d65-a5e4-4964-83cc-efb7de88a309",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import Data for predictions: In this case we are using the X_test as start data for our predictions\n",
    "#All data from API\n",
    "df = pd.read_csv(\"./Export/Test-data/DataSet.csv\", index_col='Date', infer_datetime_format=True)\n",
    "\n",
    "#Adapted X data for the different models\n",
    "X_test_rnn = pd.read_csv(\"./Export/Test-data/X_test.csv\")\n",
    "X_test_reg = X_test_rnn.iloc[:,-1]\n",
    "\n",
    "# Output data y_test\n",
    "y_test = pd.read_csv(\"./Export/Test-data/y_test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4b71e8d4-689a-4401-bfb0-9f423ed43348",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pk' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_3328/1818219561.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mfilename_x_scaler\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"./Export/X_scaler_rnn\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0minfile\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilename_x_scaler\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'rb'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m \u001b[0mX_scaler\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpk\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minfile\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m \u001b[0minfile\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'pk' is not defined"
     ]
    }
   ],
   "source": [
    "# Scale data for RNN\n",
    "#Import X_scaler from pickle\n",
    "filename_x_scaler = \"./Export/X_scaler_rnn\"\n",
    "infile = open(filename_x_scaler,'rb')\n",
    "X_scaler = pk.load(infile)\n",
    "infile.close()\n",
    "\n",
    "# Scale the testing sets\n",
    "X_test_rnn = X_scaler.transform(X_test_rnn)\n",
    "# Reshape X_test\n",
    "X_test_rnn = X_test_rnn.reshape((X_test_rnn.shape[0], X_test_rnn.shape[1], 1))\n",
    "\n",
    "\n",
    "#Import y_scaler from pickle\n",
    "filename_y_scaler = \"./Export/Y_scaler_rnn\"\n",
    "infile = open(filename_y_scaler,'rb')\n",
    "Y_scaler = pk.load(infile)\n",
    "infile.close()\n",
    "\n",
    "# Scale the testing sets\n",
    "y_test_rnn = Y_scaler.transform(y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1730178-c917-4b6c-a3aa-4fda66d8da36",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Load and predict LSTM model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16f76f38-808c-4687-978c-39839168104f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load RNN model to predict values\n",
    "from tensorflow.keras.models import model_from_json\n",
    "\n",
    "# load json and create model\n",
    "file_path = Path(\"./Export/rnn_model.json\")\n",
    "with open(file_path, \"r\") as json_file:\n",
    "    rnn_model = json_file.read()\n",
    "rnn_loaded = model_from_json(rnn_model)\n",
    "\n",
    "# load weights into new model\n",
    "file_path = \"./Export/rnn_model.h5\"\n",
    "rnn_loaded.load_weights(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb8bc943-f7e2-4624-bb4a-202f23701109",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prediction with RNN\n",
    "prediction_rnn = rnn_loaded.predict(X_test_rnn)\n",
    "predicted_prices = Y_scaler.inverse_transform(prediction_rnn)\n",
    "real_prices = Y_scaler.inverse_transform(y_test_rnn.reshape(-1, 1))\n",
    "\n",
    "# Create a DataFrame of Real and Predicted values\n",
    "nn = pd.DataFrame({\n",
    "    \"Real\": real_prices.ravel(),\n",
    "    \"Predicted\": predicted_prices.ravel()\n",
    "}, index = df.index[-len(real_prices): ]) \n",
    "\n",
    "# Plot the real vs predicted values as a line chart\n",
    "display(nn.head(),\n",
    "        nn.hvplot(title=f\"Actual Vs. Predicted Prices\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "16acb109-c6b7-4d14-9bbb-8d7f1d696a39",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Real</th>\n",
       "      <th>Predicted</th>\n",
       "      <th>real_return</th>\n",
       "      <th>predicted_return</th>\n",
       "      <th>signal_real</th>\n",
       "      <th>signal_pred</th>\n",
       "      <th>diff_signal</th>\n",
       "      <th>signal</th>\n",
       "      <th>Entry/Exit</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2022-01-07 13:00:00</th>\n",
       "      <td>41494.4</td>\n",
       "      <td>44132.238281</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-01-07 14:00:00</th>\n",
       "      <td>41898.5</td>\n",
       "      <td>43942.414062</td>\n",
       "      <td>0.009739</td>\n",
       "      <td>-0.004301</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-01-07 15:00:00</th>\n",
       "      <td>41317.1</td>\n",
       "      <td>43870.890625</td>\n",
       "      <td>-0.013876</td>\n",
       "      <td>-0.001628</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-01-07 16:00:00</th>\n",
       "      <td>42143.9</td>\n",
       "      <td>43651.699219</td>\n",
       "      <td>0.020011</td>\n",
       "      <td>-0.004996</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-01-07 17:00:00</th>\n",
       "      <td>41995.1</td>\n",
       "      <td>43708.984375</td>\n",
       "      <td>-0.003531</td>\n",
       "      <td>0.001312</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        Real     Predicted  real_return  predicted_return  \\\n",
       "Date                                                                        \n",
       "2022-01-07 13:00:00  41494.4  44132.238281          NaN               NaN   \n",
       "2022-01-07 14:00:00  41898.5  43942.414062     0.009739         -0.004301   \n",
       "2022-01-07 15:00:00  41317.1  43870.890625    -0.013876         -0.001628   \n",
       "2022-01-07 16:00:00  42143.9  43651.699219     0.020011         -0.004996   \n",
       "2022-01-07 17:00:00  41995.1  43708.984375    -0.003531          0.001312   \n",
       "\n",
       "                     signal_real  signal_pred  diff_signal  signal  Entry/Exit  \n",
       "Date                                                                            \n",
       "2022-01-07 13:00:00          NaN          NaN          NaN     0.0         NaN  \n",
       "2022-01-07 14:00:00          1.0          0.0          1.0     1.0         1.0  \n",
       "2022-01-07 15:00:00          0.0          0.0          0.0     0.0        -1.0  \n",
       "2022-01-07 16:00:00          1.0          0.0          1.0     1.0         1.0  \n",
       "2022-01-07 17:00:00          0.0          1.0         -1.0     0.0        -1.0  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Signal Strategy for RNN\n",
    "# Return for real price and prediction\n",
    "nn[\"real_return\"] = nn[\"Real\"].pct_change()\n",
    "nn[\"predicted_return\"] = nn[\"Predicted\"].pct_change()\n",
    "\n",
    "#Determine a strategy for the RNN signal\n",
    "# There is a lag in the signals, the RNN signal has always 1-2 periods delay. The signal will react with this delay (alias: reddit signal)\n",
    "# When both signal go in the same direction , then keep it.\n",
    "# When signals go in different directions (up vs down), then take the direction of the real price\n",
    "nn.loc[(nn[\"real_return\"] >= 0.0), \"signal_real\"] = 1\n",
    "nn.loc[(nn[\"real_return\"] < 0.0), \"signal_real\"] = 0\n",
    "nn.loc[(nn[\"predicted_return\"] >= 0.0), \"signal_pred\"] = 1\n",
    "nn.loc[(nn[\"predicted_return\"] < 0.0), \"signal_pred\"] = 0\n",
    "nn[\"diff_signal\"] = nn[\"signal_real\"] - nn[\"signal_pred\"]\n",
    "\n",
    "nn[\"signal\"] = 0.0\n",
    "nn.loc[(nn[\"signal_real\"] == nn[\"signal_pred\"]), \"signal\"] = nn[\"signal_real\"]\n",
    "nn.loc[(nn[\"diff_signal\"] == -1), \"signal\"] = 0\n",
    "nn.loc[(nn[\"diff_signal\"] == 1), \"signal\"] = 1\n",
    "\n",
    "nn['Entry/Exit'] = nn['signal'].diff()\n",
    "\n",
    "nn.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1d3632a-3bf1-417b-9f03-e595b3c8e1dc",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Load and predict Linear Regression model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "aacbb382-cd91-4eb2-99bc-0a05265ff614",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import y_scaler from pickle\n",
    "filename_LinReg = \"./Export/LinReg\"\n",
    "infile = open(filename_LinReg,'rb')\n",
    "LinReg = pk.load(infile)\n",
    "infile.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "b1e0632d-ade1-4332-a67d-08cf0841e402",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = np.array(y_test[\"0\"])\n",
    "er = -np.size(y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b73df5a3-810f-47e2-89cd-b463d6ddd744",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'X_test_reg' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_23880/3388594202.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# Prediction with Linear regression\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mX_reg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mX_test_reg\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_frame\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Closing_price\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mpredictions\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mLinReg\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_reg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;31m# predicted_prices = Y_scaler.inverse_transform(prediction_rnn)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'X_test_reg' is not defined"
     ]
    }
   ],
   "source": [
    "# Prediction with Linear regression\n",
    "X_reg = X_test_reg.to_frame(\"Closing_price\")\n",
    "predictions = LinReg.predict(X_reg)\n",
    "\n",
    "# predicted_prices = Y_scaler.inverse_transform(prediction_rnn)\n",
    "real_prices = np.array(y_test[\"0\"]).reshape(-1, 1)\n",
    "\n",
    "# # Create a DataFrame of Real and Predicted values\n",
    "# regression = y_test.to_frame(\"Real\")\n",
    "# regression[\"Predicted\"] = predictions\n",
    "regression = pd.DataFrame(\n",
    "    {\n",
    "    \"Real\": real_prices,\n",
    "    \"Predicted\": predictions},\n",
    "#    index = df.index[ -len(real_prices): ]\n",
    "    ) \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "f2c8bf4f-96e0-4a09-8b36-94fb5610f975",
   "metadata": {},
   "outputs": [],
   "source": [
    "# In this case, you may have to replace inf, -inf values with np.nan\"s\n",
    "X_test_reg = X_test_reg.replace(-np.inf, np.nan).dropna()\n",
    "X_test_reg = X_test_reg.replace(np.inf, np.nan).dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "417c0e44-3ece-4cfa-a750-ef76ffe64beb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d806ccca-2d72-4a91-a444-87710080fba1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Create a new column in the trading_df called signal setting its value to zero. \n",
    "# Create the signal to buy when return > 0 and sell when return < 1\n",
    "predictions_df[\"signal\"] = 0.0\n",
    "predictions_df.loc[(predictions_df[\"Difference\"] >= 0), \"signal\"] = 1\n",
    "predictions_df.loc[(predictions_df[\"Difference\"] < 0), \"signal\"] = 0\n",
    "predictions_df['Entry/Exit'] = predictions_df['signal'].diff()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "028ab210-fbb9-4671-80b4-8184b1e7f0d1",
   "metadata": {},
   "source": [
    "# Merge signals from different models to an unique signal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e0f3e41-544b-468b-ae2c-a56760a089ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Strategy : 0 sell, 1 hold,  2 buy (on signals)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6222e6fe-5847-4f49-a82e-c9340d56dc3e",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Backtesting\n",
    "1. Consider de investement ratios\n",
    "2. Calculate the actual return over the test periode"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b116c61e-316b-4739-b9d5-3a694665ef30",
   "metadata": {},
   "source": [
    "### Investement ratio's"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5298e963-59f5-4f5d-8956-ae43724a1191",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a list for the column name\n",
    "columns = [\"Backtest\"]\n",
    "\n",
    "# Create a list holding the names of the new evaluation metrics\n",
    "metrics = [\n",
    "    \"Annualized Return\",\n",
    "    \"Cumulative Returns\",\n",
    "    \"Annual Volatility\",\n",
    "    \"Sharpe Ratio\",\n",
    "    \"Sortino Ratio\"]\n",
    "\n",
    "# Initialize the DataFrame with index set to the evaluation metrics and the column\n",
    "portfolio_evaluation_df = pd.DataFrame(index=metrics, columns=columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0e9236b-53d2-4be8-9611-76bc9ab9732d",
   "metadata": {},
   "outputs": [],
   "source": [
    " # Calculate annualized return\n",
    "portfolio_evaluation_df.loc[\"Annualized Return\"] = (\n",
    "    predictions_df[\"Portfolio Daily Returns\"].mean() * 365\n",
    ")\n",
    "\n",
    " # Calculate cumulative return\n",
    "portfolio_evaluation_df.loc[\"Cumulative Returns\"] = predictions_df[\"Portfolio Cumulative Returns\"][-1]\n",
    "\n",
    " # Calculate annual volatility\n",
    "portfolio_evaluation_df.loc[\"Annual Volatility\"] = (\n",
    "    predictions_df[\"Portfolio Daily Returns\"].std() * np.sqrt(365)\n",
    ")\n",
    "\n",
    " # Calculate Sharpe ratio\n",
    "portfolio_evaluation_df.loc[\"Sharpe Ratio\"] = (\n",
    "    predictions_df[\"Portfolio Daily Returns\"].mean() * 365) / (\n",
    "    predictions_df[\"Portfolio Daily Returns\"].std() * np.sqrt(365)\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fe33666-cac7-42ae-bab1-878e0802b38e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate Sharpe ratio Sortino ratio:\n",
    "\n",
    "#First create a DataFrame that contains the Portfolio Daily Returns column and the downside return values\n",
    "sortino_ratio_df = predictions_df[[\"Portfolio Daily Returns\"]].copy()\n",
    "sortino_ratio_df.loc[:,\"Downside Returns\"] = 0\n",
    "\n",
    "# Second Find Portfolio Daily Returns values less than 0,\n",
    "# square those values, and add them to the Downside Returns column\n",
    "sortino_ratio_df.loc[sortino_ratio_df[\"Portfolio Daily Returns\"] < 0,\n",
    "                     \"Downside Returns\"] = sortino_ratio_df[\"Portfolio Daily Returns\"]**2\n",
    "\n",
    "# Then Calculate the annualized return value and the annualized downside standard deviation value\n",
    "annualized_return = (\n",
    "    sortino_ratio_df[\"Portfolio Daily Returns\"].mean() * 252)\n",
    "\n",
    "downside_standard_deviation = (\n",
    "    np.sqrt(sortino_ratio_df[\"Downside Returns\"].mean()) * np.sqrt(252))\n",
    "\n",
    "# Finally do the last calculation for the sortino_ratio\n",
    "sortino_ratio = annualized_return/downside_standard_deviation\n",
    "\n",
    "# Add the Sortino ratio to the evaluation DataFrame\n",
    "portfolio_evaluation_df.loc[\"Sortino Ratio\"] = sortino_ratio"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5ed59e0-bc73-4481-9edc-deb16aa86b1f",
   "metadata": {},
   "source": [
    "### Investement return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "682da84d-32c9-43a9-a939-1bc47253d1bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize trade evaluation DataFrame with columns\n",
    "trade_evaluation_df = pd.DataFrame(\n",
    "    columns=[\n",
    "        \"CURRENCY\",\n",
    "        \"Entry Date\",\n",
    "        \"Exit Date\",\n",
    "        \"Shares\",\n",
    "        \"Entry Share Price\",\n",
    "        \"Exit Share Price\",\n",
    "        \"Entry Portfolio Holding\",\n",
    "        \"Exit Portfolio Holding\",\n",
    "        \"Profit/Loss\"]\n",
    ")\n",
    "\n",
    "# Loop through signal DataFrame\n",
    "# If `Entry/Exit` is 1, set entry trade metrics\n",
    "# Else if `Entry/Exit` is -1, set exit trade metrics and calculate profit\n",
    "# Then append the record to the trade evaluation DataFrame\n",
    "for index, row in predictions_df.iterrows():\n",
    "    if row[\"Entry/Exit\"] == 1:\n",
    "        entry_date = index\n",
    "        entry_portfolio_holding = row[\"Portfolio Holdings\"]\n",
    "        share_size = row[\"Entry/Exit Position\"]\n",
    "        entry_share_price = row[\"close\"]\n",
    "\n",
    "    elif row[\"Entry/Exit\"] == -1:\n",
    "        exit_date = index\n",
    "        exit_portfolio_holding = abs(row[\"close\"] * row[\"Entry/Exit Position\"])\n",
    "        exit_share_price = row[\"close\"]\n",
    "        profit_loss = exit_portfolio_holding - entry_portfolio_holding\n",
    "        trade_evaluation_df = trade_evaluation_df.append(\n",
    "            {\n",
    "                \"CURRENCY\": \"ETH\",\n",
    "                \"Entry Date\": entry_date,\n",
    "                \"Exit Date\": exit_date,\n",
    "                \"Shares\": share_size,\n",
    "                \"Entry Share Price\": entry_share_price,\n",
    "                \"Exit Share Price\": exit_share_price,\n",
    "                \"Entry Portfolio Holding\": entry_portfolio_holding,\n",
    "                \"Exit Portfolio Holding\": exit_portfolio_holding,\n",
    "                \"Profit/Loss\": profit_loss\n",
    "            },\n",
    "            ignore_index=True)\n",
    "\n",
    "# Print the DataFrame\n",
    "trade_evaluation_df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
